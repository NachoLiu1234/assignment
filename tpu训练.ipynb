{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "train_tpu (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp9OUwg7Y-oJ",
        "colab_type": "code",
        "outputId": "61122500-8df7-41ff-b2f0-b2b046b2e5f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkEH3hcnUObz",
        "colab_type": "code",
        "outputId": "95422bad-af64-4ef1-ce7e-c9ada54f051a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: /opt/bin/nvidia-smi: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XJRkA3qY4jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import gensim, time\n",
        "import pickle, json\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frPtmRC3mbhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzR6i3dIY4jj",
        "colab_type": "code",
        "outputId": "d1aeaf56-4ef4-48e9-da51-00ba3861a77a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "training_path = '/content/drive/My Drive/Colab Notebooks/project2/train.pkl'\n",
        "validation_path = '/content/drive/My Drive/Colab Notebooks/project2/validation.pkl'\n",
        "word2vec_path = '/content/drive/My Drive/Colab Notebooks/project2/cn.cbow.bin'\n",
        "history_path = '/content/drive/My Drive/Colab Notebooks/project2/model/history.json'\n",
        "model_path = '/content/drive/My Drive/Colab Notebooks/project2/model/model.tf'\n",
        "\n",
        "batch_size = 8\n",
        "truncate = 450\n",
        "dimension = 300\n",
        "\n",
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu, steps_per_run=128) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker']) \n",
        "\n",
        "BATCH_SIZE = batch_size * strategy.num_replicas_in_sync # Gobal batch size.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.68.131.210:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.68.131.210:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13959921997667519874)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12124004663629699873)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10258986348942367726)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 8444659932386596494)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 925001976886473387)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 10493796680941003237)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3654329666273187251)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 13518236827893459523)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7403403119260964195)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 12940710714084043710)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2701867440547227007)\n",
            "Running on TPU  ['10.68.131.210:8470']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Miifu3UCY4jm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pickle.load(open(training_path, 'rb'))\n",
        "validation = pickle.load(open(validation_path, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHAgErRjY4jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = ['location_traffic_convenience',\n",
        "   'location_distance_from_business_district', 'location_easy_to_find',\n",
        "   'service_wait_time', 'service_waiters_attitude',\n",
        "   'service_parking_convenience', 'service_serving_speed', 'price_level',\n",
        "   'price_cost_effective', 'price_discount', 'environment_decoration',\n",
        "   'environment_noise', 'environment_space', 'environment_cleaness',\n",
        "   'dish_portion', 'dish_taste', 'dish_look', 'dish_recommendation',\n",
        "   'others_overall_experience', 'others_willing_to_consume_again']\n",
        "output = columns[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8laXLaaAY4jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[['content', output]]\n",
        "train.columns = ['x', 'y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq2gFKmoY4jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation = validation[['content', output]]\n",
        "validation.columns = ['x', 'y']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLEJAE0xY4j0",
        "colab_type": "code",
        "outputId": "d66ea757-2be1-4dc8-adef-1b5cbdd433a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True, unicode_errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "JYnulzjDY4j2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = train['x'].to_list()\n",
        "y_train = train['y'].to_list()\n",
        "x_validation = validation['x'].to_list()\n",
        "y_validation = validation['y'].to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-qN0vqFY4j4",
        "colab_type": "code",
        "outputId": "0b7cff7e-b6ce-4da1-b7fb-8ce27b1a7d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "x_train = [word2vec.wv[el]  for el in x_train]\n",
        "x_validation = [word2vec.wv[el]  for el in x_validation]\n",
        "del word2vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBsCTF3Lsk0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY7v8ATSHXj8",
        "colab_type": "code",
        "outputId": "1f4103ba-8bda-4278-f644-e984bbd4d603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "class CIFAR10Sequence(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x, y, is_x):\n",
        "      assert len(x) == len(y), '输入输出长度不匹配'\n",
        "      self.x = x\n",
        "      self.y = tf.keras.utils.to_categorical(y, 4)\n",
        "      self.add = [np.zeros(300, dtype=np.float32)]\n",
        "      self.truncate = 450\n",
        "      self.dimension = 300\n",
        "      self.is_x = is_x\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):  # (inputs, targets)\n",
        "      if self.is_x:\n",
        "        x = self.x[idx]\n",
        "        x = np.append(x, self.add * (self.truncate - x.shape[0]), axis=0) if x.shape[0] < self.truncate else x\n",
        "        return x\n",
        "      else:\n",
        "        y = self.y[idx]\n",
        "        return y\n",
        "\n",
        "class CIFAR10Sequence_batch(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x, y, batch_size):\n",
        "        self.x = x\n",
        "        self.y = tf.keras.utils.to_categorical(y, 4)\n",
        "        self.batch_size = batch_size\n",
        "        self.add = np.zeros(300)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        batch_x = [np.append(x[:truncate], np.array([self.add for _ in range(truncate - len(x))]), axis=0) if len(x) < truncate else x[:truncate] for x in batch_x]\n",
        "        batch_y = self.y[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
        "        return np.array(batch_x), np.array(batch_y)\n",
        "\n",
        "train_x = CIFAR10Sequence(x_train, y_train, is_x=1)\n",
        "train_y = CIFAR10Sequence(x_train, y_train, is_x=0)\n",
        "validation_x = CIFAR10Sequence(x_validation, y_validation, is_x=1)\n",
        "validation_y = CIFAR10Sequence(x_validation, y_validation, is_x=0)\n",
        "\n",
        "train_x[0].shape, train_y[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((450, 300), (4,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aIE4k4gE0UY",
        "colab_type": "code",
        "outputId": "a7142bb9-e734-4ec1-8bbd-6663b344081e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrSaZ3k0Dif7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen(): \n",
        "  x, y = x_train, y_train\n",
        "  add = [np.zeros(300, dtype=np.float32)]\n",
        "  for i in range(len(x)):\n",
        "    yield np.append(x[i], add * (truncate - x[i].shape[0]), axis=0) if x[i].shape[0] < truncate else x[i], y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFo_thMLDibe",
        "colab_type": "code",
        "outputId": "89c92c6c-e792-4f1a-eec5-fb98eec57059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(3) \n",
        "list(dataset.take(3)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-46fa4ae10b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzr_Q66s4ejy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_generator(gen, output_types=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfuBj8Gc4enw",
        "colab_type": "code",
        "outputId": "2c591ff4-6c7d-4ec5-b312-c6be4a3246e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "list(dataset.take(3)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-0bdc94116300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2034\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIteratorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n\u001b[0m\u001b[1;32m    344\u001b[0m                          \"or when eager execution is enabled.\")\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: __iter__() is only supported inside of tf.function or when eager execution is enabled."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OegvqM8B4eqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jLU8k8eHXnX",
        "colab_type": "code",
        "outputId": "53a3fada-1022-40ec-fe48-f52b201f1c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "INFO:tensorflow:Initializing the TPU system: 10.76.56.130:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.76.56.130:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7797236434981800356)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4520922117299518275)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4539612141356078936)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10894247709994612778)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 10669242519671235297)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 1865580206216104712)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13788888317073196342)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7763130077578124034)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 224652835634715290)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 14630786135188131972)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17760478349419103203)\n",
            "Running on TPU  ['10.76.56.130:8470']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwGxFM-OHX0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model():\n",
        "  activation = 'relu'\n",
        "  activation2 = 'relu'\n",
        "  dropout = 0.5\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "                              \n",
        "      tf.keras.layers.Conv1D(filters=16, kernel_size=3, strides=1, input_shape=(truncate, dimension)),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation),\n",
        "      tf.keras.layers.MaxPooling1D(padding='same'),\n",
        "\n",
        "      tf.keras.layers.Conv1D(filters=16, kernel_size=3, strides=1),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation),\n",
        "      tf.keras.layers.MaxPooling1D(padding='same'),\n",
        "\n",
        "      tf.keras.layers.Conv1D(filters=32, kernel_size=3, strides=1),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation),\n",
        "      tf.keras.layers.MaxPooling1D(padding='same'),\n",
        "\n",
        "      tf.keras.layers.Conv1D(filters=64, kernel_size=3, strides=1),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation),\n",
        "      tf.keras.layers.MaxPooling1D(padding='same'),\n",
        "\n",
        "      tf.keras.layers.Conv1D(filters=64, kernel_size=3, strides=1),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation),\n",
        "      tf.keras.layers.MaxPooling1D(padding='same'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "\n",
        "      tf.keras.layers.Dense(16),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation2),\n",
        "      tf.keras.layers.Dropout(dropout),\n",
        "      tf.keras.layers.Dense(8),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.Activation(activation2),\n",
        "      tf.keras.layers.Dropout(dropout),\n",
        "      tf.keras.layers.Dense(4),\n",
        "  ])\n",
        "  \n",
        "  lr = 0.01\n",
        "  model.compile(optimizer=tf.keras.optimizers.SGD(lr),\n",
        "                loss=tf.keras.losses.categorical_crossentropy,\n",
        "                metrics = ['categorical_accuracy', 'AUC', 'Precision', 'Recall'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG_5uqkzsV2s",
        "colab_type": "code",
        "outputId": "6df27c91-c3b1-4772-9263-abde1e8e7503",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model = make_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/normalization.py:625: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 448, 16)           14416     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 448, 16)           64        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 448, 16)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 224, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 222, 16)           784       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 222, 16)           64        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 222, 16)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 111, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 109, 32)           1568      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 109, 32)           128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 109, 32)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 55, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 53, 64)            6208      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 53, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 53, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 27, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 25, 64)            12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 25, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 25, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1 (None, 13, 64)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 832)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                13328     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 36        \n",
            "=================================================================\n",
            "Total params: 49,692\n",
            "Trainable params: 49,260\n",
            "Non-trainable params: 432\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ZgUdZSL4Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = tuple(x_train)\n",
        "y_train = tuple(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3IPycmFsVy9",
        "colab_type": "code",
        "outputId": "d0ba0632-e24c-4734-a1a7-32617d94186a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "steps_per_epoch = len(train) // BATCH_SIZE\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "\n",
        "def gen(): \n",
        "  x, y = x_train, y_train\n",
        "  add = [np.zeros(300, dtype=np.float32)]\n",
        "  for i in range(len(x)):\n",
        "    yield np.append(x[i], add * (truncate - x[i].shape[0]), axis=0) if x[i].shape[0] < truncate else x[i], y[i]\n",
        "\n",
        "def x_gen(): \n",
        "  x, y = x_train, y_train\n",
        "  add = [np.zeros(300, dtype=np.float32)]\n",
        "  for i in range(len(x)):\n",
        "    yield np.append(x[i], add * (truncate - x[i].shape[0]), axis=0) if x[i].shape[0] < truncate else x[i]\n",
        "\n",
        "def y_gen(): \n",
        "  x, y = x_train, y_train\n",
        "  for i in range(len(x)):\n",
        "    yield y[i]\n",
        "\n",
        "data = tf.data.Dataset.from_generator(gen, output_types=tf.float32, output_shapes=(450, 300))\n",
        "# data = tf.data.Dataset.zip((x_train, y_train)) \n",
        "data = data.batch(BATCH_SIZE, drop_remainder=True) \n",
        "x = tf.data.Dataset.from_generator(x_gen, output_types=tf.float32, output_shapes=(450, 300))\n",
        "y = tf.data.Dataset.from_generator(y_gen, output_types=tf.float32)\n",
        "# data = tf.data.Dataset.zip((x, y)) \n",
        "# data = data.batch(BATCH_SIZE, drop_remainder=True) \n",
        "\n",
        "x_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  1640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VViGZ5e9sVu1",
        "colab_type": "code",
        "outputId": "2ff62a71-b71b-456b-f09f-84061b2fa8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "history = model.fit(data, epochs=EPOCHS, steps_per_epoch=steps_per_epoch)  # , batch_size=BATCH_SIZE\n",
        "\n",
        "# final_stats = model.evaluate(validation, steps=1)\n",
        "# print(\"Validation accuracy: \", final_stats[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:absl:Operation of type Placeholder (dense_2_target_1) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg5RVchQsVrI",
        "colab_type": "code",
        "outputId": "48bf045e-d30e-45de-a1f1-4e066aee250a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIRycm3ZsVnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDmSU6AwsVjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hghSgHlxsVgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYt8FqOBsVb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e76xFjeyHX3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2j_tBPKHr7Ro",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIUg_EcsHX-0",
        "colab_type": "code",
        "outputId": "2a346415-069f-421f-cccf-bc6c167ae053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "while 1:\n",
        "  H = model.fit_generator(train, steps_per_epoch=len(train), epochs=1, validation_data=validation, validation_steps=len(validation), verbose=1)\n",
        "  model.save(model_path)\n",
        "  with open(history_path, 'a') as f:\n",
        "    f.write(json.dumps({k:[float(el) for el in v] for k, v in dict(H.history).items()}) + '\\n')\n",
        "  print('model saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11331/13125 [========================>.....] - ETA: 25s - loss: 3.1944 - categorical_accuracy: 0.2029 - auc: 1.6502e-06 - precision: 0.2177 - recall: 0.2242"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDso-i5cHXqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from_epoch = 10\n",
        "\n",
        "loss = []\n",
        "val_loss = []\n",
        "with open('/content/drive/My Drive/Colab Notebooks/ai_price_predict/cnn_dense_A_history.json', 'r') as f:\n",
        "  for line in f:\n",
        "    line = json.loads(line)\n",
        "    loss.extend(line['loss'])\n",
        "    val_loss.extend(line['val_loss'])\n",
        "assert len(loss) == len(val_loss), '检查json文件, 两个loss长度不一致'\n",
        "\n",
        "N = np.arange(0, len(loss))\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N[from_epoch:], loss[from_epoch:], label=\"train_loss\")\n",
        "plt.plot(N[from_epoch:], val_loss[from_epoch:], label=\"val_loss\")\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZU_K4ZyY4ki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N[from_epoch:], [i ** 0.5 for i in loss[from_epoch:]], label=\"train_mae\")\n",
        "plt.plot(N[from_epoch:], [i ** 0.5 for i in val_loss[from_epoch:]], label=\"val_mae\")\n",
        "plt.title(\"Training MAE\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHS4YlvzY4kk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TnZKgUEY4kl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayyQClBsY4km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0ZvH8Y2Y4ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRlJR2OyY4kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iSgJfpyY4kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AHxefE9Y4kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHvSf9c3Y4kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDSJ0kKwY4kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlRGOv2jY4ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvyeId5uY4k0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV6urU1PY4k1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym1NfByiY4k2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SunDeNoY4k5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec-hFP-5Y4k7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}